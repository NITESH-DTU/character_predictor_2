{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09834d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as f\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d18dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7ac68c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    str(name).strip().strip('\"').strip(',').lower() \n",
    "    for name in df\n",
    "    if str(name).strip().strip('\"').strip(',').isalpha()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc02edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a996bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(set(''.join(words)))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795e26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi={ s:i+1 for i,s in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0907447",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi['.']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90190e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos={ i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create the test_set\n",
    "size=3\n",
    "y=[]\n",
    "x=[]\n",
    "for i in words[:5]:\n",
    "    x_char=[0]*size\n",
    "    for j in i:\n",
    "        ch=stoi[j]\n",
    "        x.append(x_char)\n",
    "        y.append(ch)\n",
    "        char=[ itos[c] for c in x_char]\n",
    "        print(f'{''.join(char)}==> {j}')\n",
    "        x_char=x_char[1:] + [ch]\n",
    "       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "50a31135",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(x,dtype=torch.int64)\n",
    "y=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2868a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up_matrix=torch.randn((27,2),requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4766a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up_matrix[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1e278360",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=look_up_matrix[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "124dad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=emb.view(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2160fb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 6])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dc24a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.Generator().manual_seed(2147483747)\n",
    "w1=torch.randn((6,100),requires_grad=True,generator=g)\n",
    "b1=torch.randn((100),requires_grad=True,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4d7a4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2=emb@w1 +b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "816f044e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 100])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=torch.tanh(w2)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ddc4ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer_weight=torch.randn((100,27),requires_grad=True,generator=g)\n",
    "final_layer_bais=torch.randn((27),requires_grad=True,generator=g)\n",
    "logits=h@final_layer_weight + final_layer_bais\n",
    "prob_exp=torch.exp(logits)\n",
    "prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bda3b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=h@final_layer_weight + final_layer_bais\n",
    "prob_exp=torch.exp(logits)\n",
    "prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6922e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 27])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7223, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0004f25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.9671, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also rather then above ,we can use\n",
    "loss=f.cross_entropy(logits,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d0b0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n",
    "for p in parameter:\n",
    "    p.grad=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "366d570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0b2f5830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.869495391845703"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3577eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameter:\n",
    "    p.data+=-.1*p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8dd21480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameter:\n",
    "    p.grad=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the whole code together\n",
    "#static code we need\n",
    "y=[]\n",
    "x=[]\n",
    "for i in words[:5]:\n",
    "    x_char=[0]*size\n",
    "    for j in i:\n",
    "        ch=stoi[j]\n",
    "        x.append(x_char)\n",
    "        y.append(ch)\n",
    "        char=[ itos[c] for c in x_char]\n",
    "        x_char=x_char[1:] + [ch]\n",
    "x=torch.tensor(x,dtype=torch.int64)\n",
    "y=torch.tensor(y)\n",
    "g=torch.Generator().manual_seed(2147483747)\n",
    "look_up_matrix=torch.randn((27,2),requires_grad=True,generator=g)\n",
    "w1=torch.randn((6,100),requires_grad=True,generator=g)\n",
    "b1=torch.randn((100),requires_grad=True,generator=g)\n",
    "final_layer_weight=torch.randn((100,27),requires_grad=True,generator=g)\n",
    "final_layer_bais=torch.randn((27),requires_grad=True,generator=g)\n",
    "parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d327d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic code of back_pop\n",
    "for i in range(100):\n",
    "    emb=look_up_matrix[x]\n",
    "    emb=emb.view(-1,6)\n",
    "    w2=emb@w1 +b1\n",
    "    h=torch.tanh(w2)\n",
    "    logits=h@final_layer_weight + final_layer_bais\n",
    "    #prob_exp=torch.exp(logits)\n",
    "    #prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "    loss=f.cross_entropy(logits,y)\n",
    "    parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n",
    "    for p in parameter:\n",
    "        p.grad=None\n",
    "    loss.backward()\n",
    "    for p in parameter:\n",
    "        p.data+=-.1*p.grad\n",
    "    print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "57c11e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_set(word):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in words:\n",
    "        x_char=[0]*size\n",
    "        for j in i:\n",
    "            ch=stoi[j]\n",
    "            x.append(x_char)\n",
    "            y.append(ch)\n",
    "            char=[ itos[c] for c in x_char]\n",
    "            x_char=x_char[1:] + [ch]\n",
    "\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "36ea0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_training=int(0.8*len(words))\n",
    "for_testing=int(0.9*len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b5e2154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=train_set(words[:for_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d62f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test=train_set(words[for_training:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7c4f7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.Generator().manual_seed(2147483747)\n",
    "look_up_matrix=torch.randn((27,2),requires_grad=True,generator=g)\n",
    "w1=torch.randn((6,100),requires_grad=True,generator=g)\n",
    "b1=torch.randn((100),requires_grad=True,generator=g)\n",
    "final_layer_weight=torch.randn((100,27),requires_grad=True,generator=g)\n",
    "final_layer_bais=torch.randn((27),requires_grad=True,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f168ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,n):\n",
    "    x=torch.tensor(x,dtype=torch.int64)\n",
    "    y=torch.tensor(y)\n",
    "    \n",
    "    parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n",
    "    #dynamic code of back_prop\n",
    "    for i in range(n):\n",
    "        emb=look_up_matrix[x]\n",
    "        emb=emb.view(-1,6)\n",
    "        w2=emb@w1 +b1\n",
    "        h=torch.tanh(w2)\n",
    "        logits=h@final_layer_weight + final_layer_bais\n",
    "        #prob_exp=torch.exp(logits)\n",
    "        #prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "        loss=f.cross_entropy(logits,y)\n",
    "        parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n",
    "        for p in parameter:\n",
    "            p.grad=None\n",
    "        loss.backward()\n",
    "        for p in parameter:\n",
    "            p.data+=-.1*p.grad\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8f3d9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x,y):\n",
    "    x=torch.tensor(x,dtype=torch.int64)\n",
    "    y=torch.tensor(y)\n",
    "    emb=look_up_matrix[x]\n",
    "    emb=emb.view(-1,6)\n",
    "    w2=emb@w1 +b1\n",
    "    h=torch.tanh(w2)\n",
    "    logits=h@final_layer_weight + final_layer_bais\n",
    "    #prob_exp=torch.exp(logits)\n",
    "    #prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "    loss=f.cross_entropy(logits,y)\n",
    "    parameter=[look_up_matrix,w1,b1,final_layer_weight,final_layer_bais]\n",
    "    print(loss.item())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "215526a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.521152973175049\n"
     ]
    }
   ],
   "source": [
    "train(x_train,y_train,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cf725ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.520921468734741\n"
     ]
    }
   ],
   "source": [
    "test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a129585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we can se test error==train error...our model is underfitting..so lets increase parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "11945fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2=torch.Generator().manual_seed(2147483747)\n",
    "look_up_matrix2=torch.randn((27,27),requires_grad=True,generator=g2)\n",
    "w12=torch.randn((81,200),requires_grad=True,generator=g2)\n",
    "b12=torch.randn((200),requires_grad=True,generator=g2)\n",
    "final_layer_weight2=torch.randn((200,27),requires_grad=True,generator=g2)\n",
    "final_layer_bais2=torch.randn((27),requires_grad=True,generator=g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c3cab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(x,y,n):\n",
    "    x=torch.tensor(x,dtype=torch.int64)\n",
    "    y=torch.tensor(y)\n",
    "    parameter=[look_up_matrix2,w12,b12,final_layer_weight2,final_layer_bais2]\n",
    "    #dynamic code of back_pop\n",
    "    for i in range(n):\n",
    "        emb=look_up_matrix2[x]\n",
    "        emb=emb.view(-1,81)\n",
    "        w22=emb@w12 +b12\n",
    "        h=torch.tanh(w22)\n",
    "        logits=h@final_layer_weight2 + final_layer_bais2\n",
    "        #prob_exp=torch.exp(logits)\n",
    "        #prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "        loss=f.cross_entropy(logits,y)\n",
    "        for p in parameter:\n",
    "            p.grad=None\n",
    "        loss.backward()\n",
    "        for p in parameter:\n",
    "            p.data+=-.1*p.grad\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "56738ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(x,y):\n",
    "    x=torch.tensor(x,dtype=torch.int64)\n",
    "    y=torch.tensor(y)\n",
    "    emb=look_up_matrix2[x]\n",
    "    emb=emb.view(-1,81)\n",
    "    w22=emb@w12 +b12\n",
    "    h=torch.tanh(w22)\n",
    "    logits=h@final_layer_weight2 + final_layer_bais2\n",
    "    #prob_exp=torch.exp(logits)\n",
    "    #prob_exp=prob_exp/torch.sum(prob_exp,1,keepdim=True)\n",
    "    loss=f.cross_entropy(logits,y)\n",
    "    parameter=[look_up_matrix2,w12,b12,final_layer_weight2,final_layer_bais2]\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cc4d86ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.164522409439087\n"
     ]
    }
   ],
   "source": [
    "train2(x_test,y_test,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a25cfdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.164299726486206\n"
     ]
    }
   ],
   "source": [
    "test2(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dc6137ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the train2 code took 13 sec,meanwhile the train1 took 2 -3 sec max,this is due to inc in paramters and calcuations but we are far away from underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally the model is in sweet state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.14",
   "language": "python",
   "name": "py314"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
